# Sprint Plan: Gemini Provider + Multi-Account Round-Robin

**Generated:** 2025-12-27-120000
**Source STATUS:** N/A (no prior evaluation - green field features)
**Sprint Scope:** 2 deliverables (Gemini provider, multi-account failover)

---

## Executive Summary

This sprint adds two high-value features to the proxy:

1. **Gemini Provider Support** (P0) - Enable routing to Google's Gemini models via OpenAI-compatible API
2. **Multi-Account Round-Robin** (P1) - Support multiple API keys per provider with automatic failover and load balancing

**Current Implementation State:**
- ✅ Unified provider config with `format: "anthropic"|"openai"`
- ✅ Full OpenAI format conversion (Anthropic ↔ OpenAI)
- ✅ Subagent routing via system prompt hash matching
- ❌ No multi-account support (single API key per provider)
- ❌ No failover or retry logic across accounts
- ❌ No tests in proxy codebase

**Estimated Complexity:** Medium (3-5 days total)
- Gemini: Small (1-2 days) - config only, documentation
- Multi-account: Medium (3-4 days) - moderate provider refactoring, state management

---

## P0 (Critical): Gemini Provider Support

**Effort:** Small (1-2 days)
**Dependencies:** None
**Spec Reference:** User request for Gemini support • **Status Reference:** Research decision (config-only approach)

### Description

Enable routing requests to Google Gemini models by leveraging the existing OpenAI provider infrastructure. Gemini's API is OpenAI-compatible via their compatibility endpoint, so this is purely a configuration and documentation task.

The proxy already has all the plumbing needed - we just need to show users how to configure it correctly.

### Acceptance Criteria

**Configuration & Documentation:**
- [ ] Add Gemini example to `config.yaml.example` with correct base URL (`https://generativelanguage.googleapis.com/v1beta/openai/`)
- [ ] Document API key format (Gemini uses `api_key` query parameter, not Authorization header)
- [ ] Add subagent mapping example for Gemini models (e.g., `code-reviewer: "gemini:gemini-2.0-flash-exp"`)
- [ ] Document available Gemini models in comments (gemini-1.5-pro, gemini-1.5-flash, gemini-2.0-flash-exp)

**Validation:**
- [ ] Test request forwarding to Gemini API with sample agent
- [ ] Verify streaming responses work correctly
- [ ] Verify token usage is captured and displayed in dashboard
- [ ] Confirm error handling works (invalid API key, rate limits)

**User Experience:**
- [ ] Clear setup instructions in README or docs
- [ ] Troubleshooting guide for common Gemini API issues
- [ ] Example of successful Gemini routing in proxy logs

### Technical Notes

**Configuration Pattern:**
```yaml
providers:
  gemini:
    base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    api_key: "YOUR_GEMINI_API_KEY"
    format: "openai"  # Uses OpenAI compatibility layer

subagents:
  mappings:
    code-reviewer: "gemini:gemini-2.0-flash-exp"
```

**Implementation Notes:**
- No code changes required - existing `OpenAIProvider` handles all format conversion
- Gemini API quirks to document:
  - Uses API key as query parameter by default (OpenAI provider sends as Bearer token - verify this works)
  - Different rate limits than OpenAI
  - Model naming conventions differ from OpenAI
- If Bearer token auth doesn't work, may need small tweak to `openai.go` header logic

**Testing Approach:**
- Manual testing with real Gemini API key
- Test both streaming and non-streaming requests
- Verify subagent routing works end-to-end
- Check dashboard displays Gemini requests correctly

---

## P1 (High): Multi-Account Round-Robin with Failover

**Effort:** Medium (3-4 days)
**Dependencies:** None
**Spec Reference:** User request for multi-account support • **Status Reference:** Research decision (moderate changes)

### Description

Extend provider configuration to support multiple API keys per provider, with automatic round-robin load balancing and failover on errors. When one account hits rate limits or fails, the proxy automatically retries with the next available account.

This requires:
1. Config schema changes to support `api_keys: []` array
2. Provider interface extension for account management
3. Round-robin selection logic with failure tracking
4. Retry logic with account failover
5. Logging which account was used for each request

### Acceptance Criteria

**Configuration Schema:**
- [ ] Support `api_keys: ["key1", "key2", "key3"]` array in provider config
- [ ] Maintain backward compatibility with single `api_key: "xxx"` format
- [ ] Validate at startup that at least one API key is provided
- [ ] Document multi-account config in `config.yaml.example`

**Round-Robin Logic:**
- [ ] Implement round-robin selection (start with account 0, increment on each request)
- [ ] Thread-safe account selection (use mutex or atomic counter)
- [ ] Evenly distribute load across healthy accounts

**Failover Behavior:**
- [ ] On HTTP 429 (rate limit), immediately try next account (up to N total attempts)
- [ ] On HTTP 401 (invalid key), mark account as unhealthy and skip it
- [ ] On HTTP 5xx errors, retry with next account (configurable retry count)
- [ ] On network errors, retry with next account
- [ ] Track which accounts are healthy vs. unhealthy

**State Management:**
- [ ] Per-account error counters (reset after cooldown period)
- [ ] Circuit breaker pattern: temporarily disable account after N consecutive failures
- [ ] Cooldown period: re-enable unhealthy accounts after X minutes (default: 5 min)
- [ ] Health check logging: report account health status on startup and periodically

**Logging & Observability:**
- [ ] Log which account index was used for each request (e.g., "Using account 2/3")
- [ ] Log failover events (e.g., "Account 0 rate limited, trying account 1")
- [ ] Log when accounts are marked unhealthy or re-enabled
- [ ] Dashboard shows requests grouped by account (if feasible)

**Error Handling:**
- [ ] If all accounts are unhealthy, return 503 Service Unavailable with clear error
- [ ] Preserve original error message from provider in response
- [ ] Don't retry on client errors (4xx except 429)

### Technical Notes

**Config Schema Evolution:**
```yaml
providers:
  openai:
    base_url: "https://api.openai.com"
    format: "openai"
    # Option 1: Multiple keys
    api_keys:
      - "sk-abc123"
      - "sk-def456"
      - "sk-ghi789"
    # Option 2: Single key (backward compatible)
    # api_key: "sk-abc123"

    # Optional failover config
    max_retries: 3  # Per account
    cooldown_duration: "5m"  # Time before re-enabling failed account
```

**Implementation Strategy:**

1. **Config Changes** (`internal/config/config.go`):
   - Add `APIKeys []string` field to `ProviderConfig`
   - Keep `APIKey string` for backward compatibility
   - Validation: require at least one key (either `api_key` or `api_keys`)

2. **Provider Interface Extension** (`internal/provider/provider.go`):
   - Consider adding `SelectAccount()` method, or handle internally
   - OR: Make account selection transparent within `ForwardRequest()`

3. **Account Manager** (new file: `internal/provider/account_manager.go`):
   ```go
   type AccountManager struct {
       keys []string
       nextIndex int
       mutex sync.Mutex
       unhealthyUntil map[int]time.Time  // account index -> re-enable time
   }
   ```
   - Methods: `GetNextHealthyKey()`, `MarkUnhealthy(index, duration)`, `IsHealthy(index)`

4. **OpenAI Provider Refactor** (`internal/provider/openai.go`):
   - Replace single `config.APIKey` with `AccountManager`
   - In `ForwardRequest()`: loop through accounts, retry on failure
   - Update Authorization header on each retry attempt

5. **Anthropic Provider** (`internal/provider/anthropic.go`):
   - Similar refactor (uses `x-api-key` header instead of Bearer)
   - Ensure both providers use consistent failover logic

**Edge Cases:**
- What if user provides empty string in `api_keys` array? → Filter out at config load
- What if all accounts fail simultaneously? → Return 503, log critical alert
- Should cooldown be per-error-type or global? → Global cooldown simpler (start here)
- Thread safety for account selection? → Use `sync.Mutex` or `atomic.Uint32`

**Ambiguities to Resolve:**
1. **Max tokens hardcoded at 16384** (line 338 in `openai.go`) - should this be configurable per provider?
   - **Decision:** Out of scope for this sprint. Add TODO comment for future enhancement.

2. **Failover cooldown duration** - how long to wait before retrying failed account?
   - **Decision:** Default 5 minutes, configurable via `cooldown_duration: "5m"` in config.

**Testing Strategy:**
- Unit tests for `AccountManager` (round-robin, failover logic, cooldown)
- Integration test with mock HTTP server returning 429, 401, 500 errors
- Manual testing with real OpenAI accounts (if possible)
- Load test to verify even distribution across accounts

**Risk Assessment:**
- **Medium Risk:** Thread safety bugs in account selection
  - Mitigation: Use well-tested sync primitives, add unit tests
- **Low Risk:** Config parsing breaking existing setups
  - Mitigation: Maintain backward compatibility, test with old configs
- **Low Risk:** Infinite retry loops
  - Mitigation: Hard cap on total attempts (e.g., `len(api_keys) * max_retries`)

---

## Dependency Graph

```
┌─────────────────────────────────┐
│ P0: Gemini Provider Support     │
│ (Config + Docs)                 │
│ ✓ No dependencies               │
└─────────────────────────────────┘

┌─────────────────────────────────┐
│ P1: Multi-Account Round-Robin   │
│ (Provider Refactor)             │
│ ✓ No dependencies               │
└─────────────────────────────────┘
```

Both features are **independent** and can be developed in parallel or sequentially.

---

## Recommended Sprint Execution

**Day 1-2: Gemini Provider (P0)**
1. Add Gemini config examples to `config.yaml.example`
2. Write documentation for Gemini setup
3. Manual testing with real Gemini API
4. Document any quirks or gotchas

**Day 3-5: Multi-Account Round-Robin (P1)**
1. Design `AccountManager` interface and data structures
2. Update `ProviderConfig` schema with `api_keys` array
3. Implement round-robin logic with thread safety
4. Add failover retry logic to OpenAI provider
5. Port failover logic to Anthropic provider
6. Add logging and observability
7. Write unit tests for `AccountManager`
8. Integration testing with error scenarios
9. Update documentation

**Day 5+: Testing & Refinement**
- End-to-end testing of both features together
- Performance testing (ensure no latency regression)
- Documentation review
- Handle any edge cases discovered during testing

---

## Out of Scope (Deferred)

The following items were explicitly excluded from this sprint:

1. **OAuth Authentication** - Separate topic, added to roadmap
2. **Test Infrastructure** - No tests exist in proxy codebase yet; adding comprehensive test suite is a larger effort
3. **Max Tokens Configuration** - Hardcoded value in `openai.go` line 338; should be per-provider config (future enhancement)
4. **Health Check Endpoint** - API endpoint to report account health status (nice-to-have, not critical)
5. **Metrics/Prometheus** - Advanced observability (future enhancement)

---

## Risk Assessment

### High-Risk Items
None identified for this sprint scope.

### Medium-Risk Items
1. **Multi-Account Thread Safety**
   - Risk: Race conditions in account selection could cause duplicate requests or skipped accounts
   - Mitigation: Use proven synchronization primitives, thorough unit testing

2. **Failover Retry Logic**
   - Risk: Complex retry logic could introduce bugs or infinite loops
   - Mitigation: Hard caps on retry attempts, comprehensive error handling tests

### Low-Risk Items
1. **Gemini API Compatibility**
   - Risk: Gemini's "OpenAI-compatible" API may have subtle differences
   - Mitigation: Early manual testing, document known issues

2. **Config Backward Compatibility**
   - Risk: Breaking existing single-key configs
   - Mitigation: Explicit validation, support both `api_key` and `api_keys`

---

## Blockers and Questions

**Blockers:**
- None identified at this time

**Questions for Clarification:**
1. Do we need to track which account was used in the database (`RequestLog` table)?
   - **Recommendation:** Yes, add `account_index` field for debugging and analytics

2. Should cooldown duration be configurable per provider, or global?
   - **Recommendation:** Per-provider configuration for flexibility

3. Should we add health check endpoint (`/health/accounts`) for monitoring?
   - **Recommendation:** Defer to future sprint; not critical for MVP

4. How should we handle rate limit headers from provider APIs (e.g., `X-RateLimit-Remaining`)?
   - **Recommendation:** Log them, but don't implement proactive account switching based on limits (defer to future)

---

## Success Metrics

**Gemini Provider:**
- ✅ Successful request routing to Gemini API
- ✅ Streaming responses work correctly
- ✅ Token usage captured in dashboard
- ✅ Documentation clear enough for external users

**Multi-Account Round-Robin:**
- ✅ Even distribution of requests across accounts (within ±5%)
- ✅ Automatic failover on rate limits (no user-visible errors)
- ✅ Unhealthy accounts re-enabled after cooldown
- ✅ Zero race conditions or thread safety issues
- ✅ Backward compatible with single-key configs

---

## Next Steps After This Sprint

1. Add comprehensive test suite for proxy (unit + integration tests)
2. OAuth authentication flow (separate roadmap topic)
3. Health check and metrics endpoints
4. Configurable max_tokens per provider
5. Advanced routing strategies (weighted round-robin, priority-based)
