# Sprint Plan: ArchGW/Plano Integration - Research & Basic Wiring

**Generated:** 2025-12-28-034754
**Source:** STATUS-20251227_122421.md
**Topic:** integrate-archgw
**Sprint Scope:** Research + POC + Basic Integration (2-3 deliverables)

---

## Executive Summary

### Current State (from STATUS-20251227_122421.md)

The claude-code-proxy has a **fully functional provider routing system** with:
- Working Anthropic provider (passthrough, no format conversion)
- Working OpenAI provider (full Anthropic↔OpenAI format conversion)
- Subagent routing via prompt hashing
- SQLite request logging
- React dashboard for monitoring

**No ArchGW integration exists.** This is a greenfield addition.

### Goals (User Clarification)

1. **More providers**: Gemini, Qwen, etc. (ArchGW supports 11+ providers)
2. **Preference routing**: Cost/speed/quality optimization
3. **Task-specific routing**: Different providers for different tasks
4. **Deployment**: Docker is acceptable
5. **Constraint**: Must preserve Anthropic passthrough (no format conversion for Anthropic requests)

### Integration Approach

ArchGW (now Plano) runs as a **sidecar service** that the Go proxy can route to:

```
Client (Claude Code)
    |
    v
Go Proxy (port 3001)
    |
    +-- Anthropic requests → Anthropic API (passthrough, unchanged)
    +-- Subagent requests → ArchGW (new provider type) → Multi-LLM routing
    |
    v
SQLite logging + React dashboard (unchanged)
```

### Sprint Focus

This FIRST sprint focuses on **research, POC, and basic wiring**. Advanced features (preference routing, dashboard UI) are deferred to future sprints.

**Deliverables:**
1. ArchGW running locally with test routing
2. ArchGW added as a provider in Go proxy
3. Basic end-to-end request flow working

**Deferred to Future Sprints:**
- Dashboard UI for ArchGW configuration
- Preference-based routing logic (Arch-Router)
- Multi-provider failover
- Guardrails integration
- OpenTelemetry integration

---

## Gap Analysis

### Architecture Gaps

| Component | Current State | Required State | Gap |
|-----------|---------------|----------------|-----|
| ArchGW/Plano | Not installed | Running locally in Docker | No installation, no config |
| Provider support | Anthropic, OpenAI | +ArchGW as provider option | Need new provider implementation |
| Config format | providers.{name}.base_url | +ArchGW upstream URL | Minimal - follows existing pattern |
| Request routing | Direct to provider APIs | +Route to ArchGW sidecar | Need routing logic update |

### Code Changes Required

| File | Current Behavior | Required Change | Complexity |
|------|------------------|-----------------|------------|
| `proxy/internal/provider/` | Anthropic, OpenAI providers | +Add ArchGWProvider | LOW - follows existing pattern |
| `config.yaml` | providers: anthropic, openai | +Add archgw provider config | TRIVIAL |
| `proxy/internal/service/model_router.go` | Routes to named providers | Support routing to archgw | LOW - uses existing RoutingDecision |
| Docker setup | None | docker-compose.yaml for ArchGW | LOW - standard setup |

### Testing Gaps

| Test Type | Current Coverage | Required Coverage | Gap |
|-----------|------------------|-------------------|-----|
| Provider integration | Anthropic, OpenAI | +ArchGW provider tests | Need new test cases |
| E2E routing | Subagent → OpenAI | +Subagent → ArchGW → Gemini | Need integration test |
| Error handling | Provider failures | +ArchGW unavailable scenarios | Need error path tests |

---

## Work Items by Priority

---

## [P0] ArchGW Research & Local Setup

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: None
**Spec Reference**: User goals - "More providers (Gemini, Qwen, etc.)" • **Status Reference**: STATUS-20251227_122421.md §"What ArchGW/Plano Offers"

### Description

Get ArchGW/Plano running locally and understand its routing capabilities. Plano is a Rust/Envoy-based proxy that supports 11+ LLM providers including Gemini, Qwen, DeepSeek, etc. It accepts OpenAI-format requests and handles multi-provider routing.

**Key research areas:**
1. Installation: Docker vs Python CLI (`pip install planoai`)
2. Configuration: How to set up providers in `plano_config.yaml`
3. API format: Confirm it accepts OpenAI `/v1/chat/completions` requests
4. Routing modes: Model-based, alias-based, preference-aligned (Arch-Router)
5. Response format: Confirm it returns OpenAI-compatible responses

**Test criteria:**
- Successfully route a request through ArchGW to Gemini (or another non-Anthropic/OpenAI provider)
- Measure latency overhead of the extra hop
- Verify streaming responses work correctly

### Acceptance Criteria

- [ ] ArchGW/Plano running locally via Docker Compose
- [ ] plano_config.yaml configured with at least 2 providers (e.g., Gemini, Qwen)
- [ ] Test request successfully routed through ArchGW to Gemini using curl
- [ ] Streaming responses verified working
- [ ] Latency overhead measured and documented (baseline comparison)
- [ ] Configuration patterns documented (provider setup, API keys, routing rules)

### Technical Notes

**Installation options:**
```bash
# Option 1: Docker Compose (recommended for production)
docker-compose up

# Option 2: Python CLI (for development)
pip install planoai
planoai up plano_config.yaml
```

**Test request pattern:**
```bash
curl http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.0-flash-exp",
    "messages": [{"role": "user", "content": "test"}],
    "stream": true
  }'
```

**Research outputs:**
- Document ArchGW's expected request/response format
- Note any deviations from OpenAI spec
- Identify which routing mode to use for initial integration (likely model-based)

---

## [P0] Design ArchGW Provider Integration

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P0 ArchGW Research completed
**Spec Reference**: CLAUDE.md §"Architecture" - Provider interface pattern • **Status Reference**: STATUS-20251227_122421.md §"Current Provider Support"

### Description

Design how ArchGW will integrate into the existing provider architecture. The Go proxy currently has a Provider interface (`provider.go`) with two implementations:
- `AnthropicProvider` - Passthrough, no format conversion
- `OpenAIProvider` - Full Anthropic↔OpenAI format conversion

ArchGW will be a **third provider type** that:
1. Accepts Anthropic-format requests (from Claude Code)
2. Converts to OpenAI format (reuse existing conversion logic)
3. Forwards to ArchGW upstream
4. Converts OpenAI response back to Anthropic format

**Design decisions to make:**
- Should ArchGW be a provider with `format: "openai"` (reuse OpenAIProvider) or a custom ArchGWProvider?
- How to handle ArchGW-specific configuration (routing preferences, model aliases)?
- Where to inject routing logic (subagent mappings vs. model-based routing)?
- How to handle ArchGW unavailability (fallback? error?)

**Key consideration:** ArchGW only accepts OpenAI format, but we must preserve Anthropic passthrough for direct Anthropic API requests (per user constraint).

### Acceptance Criteria

- [ ] Design document created in `.agent_planning/integrate-archgw/DESIGN-archgw-provider.md`
- [ ] Provider implementation approach decided (custom vs. reuse OpenAIProvider)
- [ ] Configuration schema defined for ArchGW provider in config.yaml
- [ ] Routing decision logic specified (when to route to ArchGW vs. direct provider)
- [ ] Error handling strategy documented (ArchGW down, model unavailable, etc.)
- [ ] Integration points identified in existing codebase (files to modify, new files to create)

### Technical Notes

**Existing provider pattern** (from anthropic.go, openai.go):
```go
type Provider interface {
    Name() string
    ForwardRequest(ctx context.Context, req *http.Request) (*http.Response, error)
}
```

**Config pattern** (from config.go):
```yaml
providers:
  archgw:
    base_url: "http://localhost:8080"  # ArchGW sidecar
    format: "openai"                    # Uses OpenAI conversion
    # ArchGW-specific fields?
    routing_mode: "model"               # model | alias | preference
```

**Routing logic** (from model_router.go):
- `DetermineRoute()` returns `RoutingDecision{Provider, ProviderName, OriginalModel, TargetModel}`
- Subagent mappings: `code-reviewer: "archgw:gemini-2.0-flash-exp"`
- Must decide: Does ArchGW itself do routing, or do we route to ArchGW with a specific model?

**Format conversion:**
- Reuse existing `openai.go` conversion functions:
  - `convertAnthropicToOpenAI()` - Request conversion
  - `transformOpenAIStreamToAnthropic()` - Streaming response conversion
  - `convertOpenAIToAnthropicResponse()` - Non-streaming response conversion

---

## [P1] Implement ArchGW Provider

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0 Design completed, P0 Research completed
**Spec Reference**: CLAUDE.md §"Proxy Server" architecture • **Status Reference**: STATUS-20251227_122421.md §"Current Provider Support"

### Description

Implement the ArchGW provider following the design from the previous work item. This will be a new provider that fits into the existing provider architecture.

**Implementation scope:**
1. Create `proxy/internal/provider/archgw.go` (or reuse/extend `openai.go` if design chooses that route)
2. Update `config.yaml.example` with ArchGW example configuration
3. Update provider initialization in `cmd/proxy/main.go` to instantiate ArchGW provider
4. Update `model_router.go` to support routing to ArchGW provider
5. Handle OpenAI format conversion (request and response, streaming and non-streaming)
6. Implement error handling for ArchGW unavailability

**Test coverage:**
- Unit tests for ArchGW provider initialization
- Unit tests for request forwarding
- Integration tests for end-to-end routing (Claude Code → Go Proxy → ArchGW → Gemini)
- Error handling tests (ArchGW down, invalid model, timeout)

### Acceptance Criteria

- [ ] ArchGWProvider implemented following Provider interface
- [ ] config.yaml.example updated with archgw provider example
- [ ] Provider initialization in main.go includes ArchGW
- [ ] Subagent mapping supports archgw provider (e.g., `code-reviewer: "archgw:gemini-2.0-flash-exp"`)
- [ ] Request format conversion working (Anthropic → OpenAI for ArchGW)
- [ ] Response format conversion working (OpenAI → Anthropic, streaming and non-streaming)
- [ ] Error handling implemented (ArchGW unavailable returns clear error)
- [ ] Unit tests added for ArchGW provider
- [ ] Integration test passes: curl to Go proxy → routes through ArchGW → returns valid response
- [ ] Existing tests still pass (Anthropic passthrough unchanged)
- [ ] SQLite logging captures ArchGW requests correctly

### Technical Notes

**Implementation pattern** (follow anthropic.go structure):
```go
// proxy/internal/provider/archgw.go
type ArchGWProvider struct {
    name   string
    client *http.Client
    config *config.ProviderConfig
}

func NewArchGWProvider(name string, cfg *config.ProviderConfig) Provider {
    return &ArchGWProvider{
        name:   name,
        client: &http.Client{Timeout: 300 * time.Second},
        config: cfg,
    }
}

func (p *ArchGWProvider) ForwardRequest(ctx context.Context, req *http.Request) (*http.Response, error) {
    // 1. Convert Anthropic request body to OpenAI format
    // 2. Forward to ArchGW base_url
    // 3. Handle streaming/non-streaming responses
    // 4. Convert OpenAI response back to Anthropic format
    // 5. Return response
}
```

**Config example** (add to config.yaml.example):
```yaml
providers:
  archgw:
    base_url: "http://localhost:8080"
    format: "openai"

subagents:
  mappings:
    code-reviewer: "archgw:gemini-2.0-flash-exp"
    planner: "archgw:qwen-max"
```

**Testing approach:**
1. Unit test provider initialization
2. Unit test request forwarding logic
3. Integration test with real ArchGW instance
4. Error path tests (mock ArchGW unavailable)

**Gotchas:**
- ArchGW expects OpenAI format, so must convert before forwarding
- Must preserve streaming SSE format through the conversion pipeline
- Error responses from ArchGW might be in OpenAI format, need to convert to Anthropic format
- Logging should capture both the original Anthropic request and the converted OpenAI request to ArchGW

---

## [P2] Create Docker Compose Setup

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P0 Research completed
**Spec Reference**: User goals - "Docker is acceptable" • **Status Reference**: STATUS-20251227_122421.md §"Deployment Constraints"

### Description

Create a Docker Compose configuration that runs both the Go proxy and ArchGW as services. This simplifies deployment and ensures ArchGW is available when the proxy starts.

**Services:**
1. `proxy` - Go proxy server (existing, needs Dockerfile if not present)
2. `archgw` - ArchGW/Plano service
3. `web` - React dashboard (existing)

**Networking:**
- Proxy communicates with ArchGW via internal Docker network
- Proxy and web exposed to host
- ArchGW not exposed to host (internal only)

**Configuration:**
- Mount `config.yaml` into proxy container
- Mount `plano_config.yaml` into ArchGW container
- Shared volume for SQLite database between proxy and web

### Acceptance Criteria

- [ ] docker-compose.yaml created at repository root
- [ ] ArchGW service defined with correct image and config mount
- [ ] Proxy service updated to reference ArchGW via Docker network
- [ ] Web service integrated into compose setup
- [ ] Environment variables documented in .env.example
- [ ] Volumes configured for persistent data (SQLite DB)
- [ ] Health checks added for all services
- [ ] README.md updated with Docker Compose usage instructions
- [ ] `make docker-up` and `make docker-down` commands added to Makefile
- [ ] Verified: `docker-compose up` starts all services successfully
- [ ] Verified: End-to-end request works through Docker setup

### Technical Notes

**Docker Compose structure:**
```yaml
services:
  archgw:
    image: katanemo/plano:latest  # Or planoai/plano, verify from research
    volumes:
      - ./plano_config.yaml:/app/plano_config.yaml
    networks:
      - proxy-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  proxy:
    build: ./proxy
    ports:
      - "3001:3001"
    volumes:
      - ./config.yaml:/app/config.yaml
      - ./requests.db:/app/requests.db
    environment:
      - ARCHGW_BASE_URL=http://archgw:8080
    depends_on:
      archgw:
        condition: service_healthy
    networks:
      - proxy-net

  web:
    build: ./web
    ports:
      - "5173:5173"  # Vite dev server
    volumes:
      - ./requests.db:/app/requests.db
    depends_on:
      - proxy
    networks:
      - proxy-net

networks:
  proxy-net:
    driver: bridge
```

**Config updates:**
- Update `config.yaml.example` to show Docker network URLs
- Create `plano_config.yaml.example` with multi-provider setup
- Document environment variable overrides

**Makefile additions:**
```makefile
docker-up:
	docker-compose up -d

docker-down:
	docker-compose down

docker-logs:
	docker-compose logs -f
```

---

## Deferred Work (Future Sprints)

These items are explicitly OUT OF SCOPE for this sprint:

### Dashboard UI for ArchGW Configuration
- Web interface to configure ArchGW provider settings
- UI for managing subagent → ArchGW model mappings
- Real-time ArchGW status monitoring

**Reason for deferral:** Backend integration must work first. UI is lower priority.

### Preference-Based Routing
- Integrate Arch-Router (1.5B model) for intelligent routing
- Cost/speed/quality optimization logic
- Dynamic model selection based on request context

**Reason for deferral:** Basic model-based routing is sufficient for MVP. Preference routing is a power feature.

### Multi-Provider Failover
- Fallback logic if ArchGW is unavailable
- Automatic retry with different provider
- Circuit breaker pattern

**Reason for deferral:** Single provider routing is sufficient for POC. Reliability features come later.

### Guardrails Integration
- Jailbreak detection via ArchGW
- Content moderation filters
- Safety scoring

**Reason for deferral:** Security features are important but not blocking for basic integration.

### OpenTelemetry Integration
- Distributed tracing for requests through Go proxy → ArchGW → LLM
- Metrics export to observability platform
- Performance monitoring dashboards

**Reason for deferral:** Current SQLite logging is sufficient for now. Observability is a future enhancement.

---

## Dependency Graph

```
P0: ArchGW Research
    |
    v
P0: Design ArchGW Provider  ----+
    |                            |
    v                            v
P1: Implement ArchGW Provider   P2: Docker Compose Setup
```

**Critical path:** P0 Research → P0 Design → P1 Implement

**Parallel work:** P2 Docker Compose can be done alongside P1 Implement after P0 Research completes.

---

## Risk Assessment

### High-Risk Items

| Risk | Impact | Mitigation |
|------|--------|------------|
| ArchGW format incompatibility | BLOCKS integration | P0 Research validates format compatibility early |
| Performance regression from extra hop | User-visible latency | Measure latency in P0 Research, set acceptable threshold |
| Breaking existing Anthropic passthrough | HIGH - core requirement | Comprehensive tests ensure passthrough unchanged |

### Medium-Risk Items

| Risk | Impact | Mitigation |
|------|--------|------------|
| ArchGW Docker deployment issues | Deployment complexity | Test Docker setup in P2, document troubleshooting |
| Config management complexity | Developer friction | Keep config simple, use sensible defaults |
| Error handling edge cases | Poor user experience | Thorough error path testing in P1 |

### Low-Risk Items

| Risk | Impact | Mitigation |
|------|--------|------------|
| OpenAI conversion reuse issues | Implementation delay | Existing conversion code well-tested |
| SQLite logging for ArchGW requests | Monitoring gap | Follows existing logging pattern |

---

## Success Metrics

This sprint will be considered successful when:

1. **ArchGW running locally** - `docker-compose up` starts ArchGW successfully
2. **Provider integration working** - Subagent request routes through ArchGW to Gemini
3. **Format conversion correct** - OpenAI responses converted back to Anthropic format
4. **Logging functional** - ArchGW requests appear in SQLite DB and dashboard
5. **Anthropic passthrough unchanged** - Direct Anthropic requests still work without format conversion
6. **Tests passing** - All existing tests pass + new ArchGW tests pass
7. **Latency acceptable** - Extra hop adds <100ms overhead (to be validated in P0 Research)

**Definition of Done:** All P0 and P1 items completed with acceptance criteria met. P2 is nice-to-have but not blocking.

---

## Next Steps (Post-Sprint)

After this sprint completes, recommended follow-up work:

1. **Sprint 2: Preference Routing** - Integrate Arch-Router for cost/speed/quality optimization
2. **Sprint 3: Dashboard UI** - Add web interface for ArchGW configuration
3. **Sprint 4: Reliability** - Implement failover, circuit breakers, health checks
4. **Sprint 5: Observability** - OpenTelemetry integration for distributed tracing

---

## Questions for User (If Any Arise During Implementation)

- Is 100ms latency overhead acceptable for ArchGW routing?
- Which providers should be configured by default in plano_config.yaml?
- Should ArchGW be opt-in (disabled by default) or opt-out?
- What's the priority order for additional providers (Gemini > Qwen > DeepSeek > ...)?
