# LLM Proxy Configuration Example

# Provider configurations
# New style: allows declaring arbitrary providers and their "format" will be either "openai" or "anthropic"
providers:
  anthropic:
    base_url: "https://api.anthropic.com"
    max_retries: 3
    format: "anthropic" # required

  zai:
    base_url: "https://api.z.ai/api/anthropic"
    api_key: "xxx"
    format: "anthropic" # required
  
  openai:
    api_key: "..."
    base_url: "https://api.openai.com"
    format: "openai" #required

  localllm:
    base_url: "localhost:1234"
    format: "openai" # required 

# Subagent Configuration
# New style: We must refer to the specific provider as well as the model
subagents:
  mappings:
    # <agent name>: "<provider name>:<model name>"
    code-reviewer: "openai:gpt-4o"
    planner: "localllm:my-local-agent"
    janitor: "zai:glm-4.6"

# NOTE: OLD CONFIGS ARE NOT SUPPORTED.