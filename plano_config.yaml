# Plano Configuration for claude-code-proxy integration testing
# Reference: https://docs.planoai.dev/concepts/llm_providers/supported_providers.html

version: v0.1.0

listeners:
  - name: egress_traffic
    address: 0.0.0.0
    port: 8080
    message_format: openai
    timeout: 30s

# Configure multiple LLM providers for testing
# Provider prefixes: openai/, anthropic/, deepseek/, gemini/, mistral/, groq/
llm_providers:
  # OpenAI GPT-4o (baseline for comparison)
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: general_purpose
        description: General purpose tasks, high quality responses
      - name: complex_reasoning
        description: Deep analysis, mathematical problem solving

  # OpenAI GPT-4o-mini (cost-effective option)
  - model: openai/gpt-4o-mini
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: cost_effective
        description: Cost-effective tasks, quick responses
      - name: simple_code
        description: Simple code generation and basic tasks

  # Google Gemini 2.0 Flash (fast, experimental)
  - model: gemini/gemini-2.0-flash-exp
    access_key: $GEMINI_API_KEY
    routing_preferences:
      - name: fast_generation
        description: Fast code generation, quick responses
      - name: experimental
        description: Testing new model capabilities

  # DeepSeek Chat (cost-effective, code-focused)
  - model: deepseek/deepseek-chat
    access_key: $DEEPSEEK_API_KEY
    routing_preferences:
      - name: code_analysis
        description: Code analysis, understanding existing code
      - name: budget_friendly
        description: Cost-effective general tasks

  # DeepSeek Coder (specialized for code)
  - model: deepseek/deepseek-coder
    access_key: $DEEPSEEK_API_KEY
    routing_preferences:
      - name: code_generation
        description: Generating new code, writing functions
      - name: code_review
        description: Analyzing code for bugs and improvements
